{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import wave\n",
    "import pyaudio\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_audio(filename):\n",
    "    rec_time = 3            # 録音時間[s]\n",
    "\n",
    "    file_path = filename \n",
    "    fmt = pyaudio.paInt16  # 音声のフォーマット\n",
    "    ch = 1              # チャンネル1(モノラル)\n",
    "    sampling_rate = 44100 # サンプリング周波数\n",
    "    chunk = 2**11       # チャンク（データ点数）\n",
    "    audio = pyaudio.PyAudio()\n",
    "    index = 1 # 録音デバイスのインデックス番号（デフォルト1）\n",
    "\n",
    "    stream = audio.open(format=fmt, channels=ch, rate=sampling_rate, input=True,\n",
    "                        input_device_index = index,\n",
    "                        frames_per_buffer=chunk)\n",
    "    # 録音処理\n",
    "    frames = []\n",
    "    for i in range(0, int(sampling_rate / chunk * rec_time)):\n",
    "        data = stream.read(chunk)\n",
    "        frames.append(data)\n",
    "\n",
    "    # 録音終了処理\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # 録音データをファイルに保存\n",
    "    wav = wave.open(file_path, 'wb')\n",
    "    wav.setnchannels(ch)\n",
    "    wav.setsampwidth(audio.get_sample_size(fmt))\n",
    "    wav.setframerate(sampling_rate)\n",
    "    wav.writeframes(b''.join(frames))\n",
    "    wav.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wave_load(filename):\n",
    "    # open wave file\n",
    "    wf = wave.open(filename,'r')\n",
    "    channels = wf.getnchannels()\n",
    "\n",
    "    # load wave data\n",
    "    chunk_size = wf.getnframes()\n",
    "    amp  = (2**8) ** wf.getsampwidth() / 2\n",
    "    data = wf.readframes(chunk_size)   # バイナリ読み込み\n",
    "    data = np.frombuffer(data,'int16') # intに変換\n",
    "    data = data / amp                  # 振幅正規化\n",
    "    data = data[::channels]\n",
    "   \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fft_load(size,filename):\n",
    "    '''\n",
    "    st = サンプリング開始位置 [s]\n",
    "    size = FFTのサンプル数（２＊＊ｎ）\n",
    "    filename = オーディオファイルのディレクトリ\n",
    "\n",
    "    '''\n",
    "    #st=44100*st\n",
    "    \n",
    "    \n",
    "    hammingWindow = np.hamming(size)    # ハミング窓\n",
    "    fs = 44100 #サンプリングレート\n",
    "    d = 1.0 / fs #サンプリングレートの逆数\n",
    "    freqList = np.fft.fftfreq(size, d)\n",
    "    \n",
    "    wave = wave_load(filename)\n",
    "    #print(len(wave))\n",
    "    \n",
    "    #10000Hzごとにサンプルを10点取ってそれを平均したものを学習用の音声スペクトルデータとして用いる。\n",
    "    for i in range(10):\n",
    "        st=i*10000\n",
    "        windowedData = hammingWindow * wave[st:st+size]  # 切り出した波形データ（窓関数あり）\n",
    "        sample_data = np.fft.fft(windowedData)\n",
    "        sample_data = sample_data / max(abs(sample_data)) # 0~1正規化\n",
    "        if(i==0):\n",
    "            data = sample_data\n",
    "        else:\n",
    "            data = (i*data+sample_data)/(i+1)\n",
    "    \n",
    "    data=abs(data)/max(abs(data))\n",
    "    #print(type(data[0]))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### modelの読み出し "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model(\"./model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# リアルタイムで温度測定をしてみる。\n",
    "---\n",
    "インターバルを挟み、一旦音声ファイルを録音した上でスペクトルを学習にかける。  \n",
    "出来れば音声保存を介さずに処理したい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "処理開始\n",
      "1回目の処理が終了\n",
      "2回目の処理が終了\n",
      "3回目の処理が終了\n",
      "4回目の処理が終了\n",
      "5回目の処理が終了\n",
      "6回目の処理が終了\n",
      "7回目の処理が終了\n",
      "8回目の処理が終了\n",
      "9回目の処理が終了\n",
      "10回目の処理が終了\n",
      "11回目の処理が終了\n",
      "12回目の処理が終了\n",
      "13回目の処理が終了\n",
      "14回目の処理が終了\n",
      "15回目の処理が終了\n",
      "16回目の処理が終了\n",
      "17回目の処理が終了\n",
      "18回目の処理が終了\n",
      "19回目の処理が終了\n",
      "20回目の処理が終了\n",
      "21回目の処理が終了\n",
      "22回目の処理が終了\n",
      "23回目の処理が終了\n",
      "24回目の処理が終了\n",
      "25回目の処理が終了\n",
      "26回目の処理が終了\n",
      "27回目の処理が終了\n",
      "28回目の処理が終了\n",
      "29回目の処理が終了\n",
      "30回目の処理が終了\n",
      "31回目の処理が終了\n",
      "32回目の処理が終了\n",
      "33回目の処理が終了\n",
      "34回目の処理が終了\n",
      "35回目の処理が終了\n",
      "36回目の処理が終了\n",
      "37回目の処理が終了\n",
      "38回目の処理が終了\n",
      "39回目の処理が終了\n",
      "40回目の処理が終了\n",
      "41回目の処理が終了\n",
      "42回目の処理が終了\n",
      "43回目の処理が終了\n",
      "44回目の処理が終了\n",
      "45回目の処理が終了\n",
      "46回目の処理が終了\n",
      "47回目の処理が終了\n",
      "48回目の処理が終了\n",
      "49回目の処理が終了\n",
      "50回目の処理が終了\n",
      "51回目の処理が終了\n",
      "52回目の処理が終了\n",
      "53回目の処理が終了\n",
      "54回目の処理が終了\n",
      "55回目の処理が終了\n",
      "56回目の処理が終了\n",
      "57回目の処理が終了\n",
      "58回目の処理が終了\n",
      "\n",
      "\n",
      "5.18,29.66\n",
      "10.35,28.96\n",
      "15.53,26.45\n",
      "20.72,31.87\n",
      "25.90,37.33\n",
      "31.10,31.00\n",
      "36.27,31.57\n",
      "41.45,33.29\n",
      "46.62,35.32\n",
      "51.80,36.17\n",
      "56.98,36.06\n",
      "62.15,43.76\n",
      "67.33,34.06\n",
      "72.51,45.51\n",
      "77.69,54.29\n",
      "82.86,51.73\n",
      "88.04,42.56\n",
      "93.22,55.64\n",
      "98.40,59.43\n",
      "103.58,51.61\n",
      "108.76,62.59\n",
      "113.93,46.95\n",
      "119.11,44.60\n",
      "124.28,57.50\n",
      "129.46,58.38\n",
      "134.64,59.50\n",
      "139.81,49.78\n",
      "144.99,52.51\n",
      "150.17,61.65\n",
      "155.34,65.90\n",
      "160.51,55.28\n",
      "165.68,60.57\n",
      "170.86,46.66\n",
      "176.03,56.00\n",
      "181.21,65.86\n",
      "186.39,44.26\n",
      "196.74,50.28\n",
      "201.91,61.11\n",
      "207.09,61.52\n",
      "212.27,61.94\n",
      "217.44,70.46\n",
      "222.61,62.44\n",
      "227.79,66.85\n",
      "232.97,65.25\n",
      "238.15,65.28\n",
      "243.32,52.09\n"
     ]
    }
   ],
   "source": [
    "filename=\"./t_fal_audio/sound_data.wav\"\n",
    "size=2**12\n",
    "\n",
    "interval=2 #何秒間インターバルを挟むか？ 1回：録音時間3s＋インターバル\n",
    "\n",
    "temp_set=np.array([])\n",
    "time_set=np.array([])\n",
    "\n",
    "start_time=time.time()\n",
    "lap_time=0\n",
    "\n",
    "i=0\n",
    "while(300-lap_time>0):\n",
    "    if(i==0):print(\"処理開始\")\n",
    "    \n",
    "    time.sleep(interval)\n",
    "    \n",
    "    rec_audio(filename)\n",
    "    data=fft_load(size, filename)\n",
    "    data=data.reshape(1,4096)\n",
    "    \n",
    "    temp=model.predict(data)*100\n",
    "    lap_time=time.time()-start_time\n",
    "    \n",
    "    temp_set=np.append(temp_set, temp)\n",
    "    time_set=np.append(time_set, lap_time)\n",
    "    \n",
    "    i+=1\n",
    "    print(\"{num}回目の処理が終了\".format(num=i))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for i in range(len(time_set)):\n",
    "    print(\"{0:.2f},{1:.2f}\".format(time_set[i], temp_set[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
